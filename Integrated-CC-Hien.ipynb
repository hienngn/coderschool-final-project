{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is intended to be an end-to-end pipeline\n",
    "\n",
    "### Checklist for deployment\n",
    "\n",
    "- [ ] Copy `net` and `utils` to main dir. \n",
    "- [ ] Compile `bbox` in the `utils` folder\n",
    "- [ ] Remember to `pip install future`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dewarp Experiment\n",
    "To use page_dewarp(\"/path/to/image.jpg\"), make sure to install `pip install future`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from tqdm import tqdm\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cedric/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/cedric/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import zip\n",
    "from builtins import str\n",
    "from builtins import range\n",
    "from builtins import object\n",
    "from past.utils import old_div\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for some reason pylint complains about cv2 members being undefined :(\n",
    "# pylint: disable=E1101\n",
    "\n",
    "PAGE_MARGIN_X = 40       # reduced px to ignore near L/R edge\n",
    "PAGE_MARGIN_Y = 20       # reduced px to ignore near T/B edge\n",
    "\n",
    "OUTPUT_ZOOM = 1.0        # how much to zoom output relative to *original* image\n",
    "OUTPUT_DPI = 300         # just affects stated DPI of PNG, not appearance\n",
    "REMAP_DECIMATE = 16      # downscaling factor for remapping image\n",
    "\n",
    "ADAPTIVE_WINSZ = 55      # window size for adaptive threshold in reduced px\n",
    "\n",
    "TEXT_MIN_WIDTH = 15      # min reduced px width of detected text contour\n",
    "TEXT_MIN_HEIGHT = 2      # min reduced px height of detected text contour\n",
    "TEXT_MIN_ASPECT = 1.5    # filter out text contours below this w/h ratio\n",
    "TEXT_MAX_THICKNESS = 10  # max reduced px thickness of detected text contour\n",
    "\n",
    "EDGE_MAX_OVERLAP = 1.0   # max reduced px horiz. overlap of contours in span\n",
    "EDGE_MAX_LENGTH = 100.0  # max reduced px length of edge connecting contours\n",
    "EDGE_ANGLE_COST = 10.0   # cost of angles in edges (tradeoff vs. length)\n",
    "EDGE_MAX_ANGLE = 7.5     # maximum change in angle allowed between contours\n",
    "\n",
    "RVEC_IDX = slice(0, 3)   # index of rvec in params vector\n",
    "TVEC_IDX = slice(3, 6)   # index of tvec in params vector\n",
    "CUBIC_IDX = slice(6, 8)  # index of cubic slopes in params vector\n",
    "\n",
    "SPAN_MIN_WIDTH = 30      # minimum reduced px width for span\n",
    "SPAN_PX_PER_STEP = 20    # reduced px spacing for sampling along spans\n",
    "FOCAL_LENGTH = 1.2       # normalized focal length of camera\n",
    "\n",
    "DEBUG_LEVEL = 0          # 0=none, 1=some, 2=lots, 3=all\n",
    "DEBUG_OUTPUT = 'file'    # file, screen, both\n",
    "\n",
    "WINDOW_NAME = 'Dewarp'   # Window name for visualization\n",
    "\n",
    "# nice color palette for visualizing contours, etc.\n",
    "CCOLORS = [\n",
    "    (255, 0, 0),\n",
    "    (255, 63, 0),\n",
    "    (255, 127, 0),\n",
    "    (255, 191, 0),\n",
    "    (255, 255, 0),\n",
    "    (191, 255, 0),\n",
    "    (127, 255, 0),\n",
    "    (63, 255, 0),\n",
    "    (0, 255, 0),\n",
    "    (0, 255, 63),\n",
    "    (0, 255, 127),\n",
    "    (0, 255, 191),\n",
    "    (0, 255, 255),\n",
    "    (0, 191, 255),\n",
    "    (0, 127, 255),\n",
    "    (0, 63, 255),\n",
    "    (0, 0, 255),\n",
    "    (63, 0, 255),\n",
    "    (127, 0, 255),\n",
    "    (191, 0, 255),\n",
    "    (255, 0, 255),\n",
    "    (255, 0, 191),\n",
    "    (255, 0, 127),\n",
    "    (255, 0, 63),\n",
    "]\n",
    "\n",
    "# default intrinsic parameter matrix\n",
    "K = np.array([\n",
    "    [FOCAL_LENGTH, 0, 0],\n",
    "    [0, FOCAL_LENGTH, 0],\n",
    "    [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "\n",
    "def debug_show(name, step, text, display):\n",
    "\n",
    "    if DEBUG_OUTPUT != 'screen':\n",
    "        filetext = text.replace(' ', '_')\n",
    "        outfile = name + '_debug_' + str(step) + '_' + filetext + '.png'\n",
    "        cv2.imwrite(outfile, display)\n",
    "\n",
    "    if DEBUG_OUTPUT != 'file':\n",
    "\n",
    "        image = display.copy()\n",
    "        height = image.shape[0]\n",
    "\n",
    "        cv2.putText(image, text, (16, height-16),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                    (0, 0, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(image, text, (16, height-16),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                    (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(WINDOW_NAME, image)\n",
    "\n",
    "        while cv2.waitKey(5) < 0:\n",
    "            pass\n",
    "\n",
    "\n",
    "def round_nearest_multiple(i, factor):\n",
    "    i = int(i)\n",
    "    rem = i % factor\n",
    "    if not rem:\n",
    "        return i\n",
    "    else:\n",
    "        return i + factor - rem\n",
    "\n",
    "\n",
    "def pix2norm(shape, pts):\n",
    "    height, width = shape[:2]\n",
    "    scl = 2.0/(max(height, width))\n",
    "    offset = np.array([width, height], dtype=pts.dtype).reshape((-1, 1, 2))*0.5\n",
    "    return (pts - offset) * scl\n",
    "\n",
    "\n",
    "def norm2pix(shape, pts, as_integer):\n",
    "    height, width = shape[:2]\n",
    "    scl = max(height, width)*0.5\n",
    "    offset = np.array([0.5*width, 0.5*height],\n",
    "                      dtype=pts.dtype).reshape((-1, 1, 2))\n",
    "    rval = pts * scl + offset\n",
    "    if as_integer:\n",
    "        return (rval + 0.5).astype(int)\n",
    "    else:\n",
    "        return rval\n",
    "\n",
    "\n",
    "def fltp(point):\n",
    "    return tuple(point.astype(int).flatten())\n",
    "\n",
    "\n",
    "def draw_correspondences(img, dstpoints, projpts):\n",
    "\n",
    "    display = img.copy()\n",
    "    dstpoints = norm2pix(img.shape, dstpoints, True)\n",
    "    projpts = norm2pix(img.shape, projpts, True)\n",
    "\n",
    "    for pts, color in [(projpts, (255, 0, 0)),\n",
    "                       (dstpoints, (0, 0, 255))]:\n",
    "\n",
    "        for point in pts:\n",
    "            cv2.circle(display, fltp(point), 3, color, -1, cv2.LINE_AA)\n",
    "\n",
    "    for point_a, point_b in zip(projpts, dstpoints):\n",
    "        cv2.line(display, fltp(point_a), fltp(point_b),\n",
    "                 (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    return display\n",
    "\n",
    "\n",
    "def get_default_params(corners, ycoords, xcoords):\n",
    "\n",
    "    # page width and height\n",
    "    page_width = np.linalg.norm(corners[1] - corners[0])\n",
    "    page_height = np.linalg.norm(corners[-1] - corners[0])\n",
    "    rough_dims = (page_width, page_height)\n",
    "\n",
    "    # our initial guess for the cubic has no slope\n",
    "    cubic_slopes = [0.0, 0.0]\n",
    "\n",
    "    # object points of flat page in 3D coordinates\n",
    "    corners_object3d = np.array([\n",
    "        [0, 0, 0],\n",
    "        [page_width, 0, 0],\n",
    "        [page_width, page_height, 0],\n",
    "        [0, page_height, 0]])\n",
    "\n",
    "    # estimate rotation and translation from four 2D-to-3D point\n",
    "    # correspondences\n",
    "    _, rvec, tvec = cv2.solvePnP(corners_object3d,\n",
    "                                 corners, K, np.zeros(5))\n",
    "\n",
    "    span_counts = [len(xc) for xc in xcoords]\n",
    "\n",
    "    params = np.hstack((np.array(rvec).flatten(),\n",
    "                        np.array(tvec).flatten(),\n",
    "                        np.array(cubic_slopes).flatten(),\n",
    "                        ycoords.flatten()) +\n",
    "                       tuple(xcoords))\n",
    "\n",
    "    return rough_dims, span_counts, params\n",
    "\n",
    "\n",
    "def project_xy(xy_coords, pvec):\n",
    "\n",
    "    # get cubic polynomial coefficients given\n",
    "    #\n",
    "    #  f(0) = 0, f'(0) = alpha\n",
    "    #  f(1) = 0, f'(1) = beta\n",
    "\n",
    "    alpha, beta = tuple(pvec[CUBIC_IDX])\n",
    "\n",
    "    poly = np.array([\n",
    "        alpha + beta,\n",
    "        -2*alpha - beta,\n",
    "        alpha,\n",
    "        0])\n",
    "\n",
    "    xy_coords = xy_coords.reshape((-1, 2))\n",
    "    z_coords = np.polyval(poly, xy_coords[:, 0])\n",
    "\n",
    "    objpoints = np.hstack((xy_coords, z_coords.reshape((-1, 1))))\n",
    "\n",
    "    image_points, _ = cv2.projectPoints(objpoints,\n",
    "                                        pvec[RVEC_IDX],\n",
    "                                        pvec[TVEC_IDX],\n",
    "                                        K, np.zeros(5))\n",
    "\n",
    "    return image_points\n",
    "\n",
    "\n",
    "def project_keypoints(pvec, keypoint_index):\n",
    "\n",
    "    xy_coords = pvec[keypoint_index]\n",
    "    xy_coords[0, :] = 0\n",
    "\n",
    "    return project_xy(xy_coords, pvec)\n",
    "\n",
    "\n",
    "def resize_to_screen(src, maxw=1280, maxh=700, copy=False):\n",
    "\n",
    "    height, width = src.shape[:2]\n",
    "\n",
    "    scl_x = float(width)/maxw\n",
    "    scl_y = float(height)/maxh\n",
    "\n",
    "    scl = int(np.ceil(max(scl_x, scl_y)))\n",
    "\n",
    "    if scl > 1.0:\n",
    "        inv_scl = 1.0/scl\n",
    "        img = cv2.resize(src, (0, 0), None, inv_scl, inv_scl, cv2.INTER_AREA)\n",
    "    elif copy:\n",
    "        img = src.copy()\n",
    "    else:\n",
    "        img = src\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def box(width, height):\n",
    "    return np.ones((height, width), dtype=np.uint8)\n",
    "\n",
    "\n",
    "def get_page_extents(small):\n",
    "\n",
    "    height, width = small.shape[:2]\n",
    "\n",
    "    xmin = PAGE_MARGIN_X\n",
    "    ymin = PAGE_MARGIN_Y\n",
    "    xmax = width-PAGE_MARGIN_X\n",
    "    ymax = height-PAGE_MARGIN_Y\n",
    "\n",
    "    page = np.zeros((height, width), dtype=np.uint8)\n",
    "    cv2.rectangle(page, (xmin, ymin), (xmax, ymax), (255, 255, 255), -1)\n",
    "\n",
    "    outline = np.array([\n",
    "        [xmin, ymin],\n",
    "        [xmin, ymax],\n",
    "        [xmax, ymax],\n",
    "        [xmax, ymin]])\n",
    "\n",
    "    return page, outline\n",
    "\n",
    "\n",
    "def get_mask(name, small, pagemask, masktype):\n",
    "\n",
    "    sgray = cv2.cvtColor(small, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if masktype == 'text':\n",
    "        \n",
    "        #mask = cv2.adaptiveThreshold(sgray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 4)\n",
    "        mask = cv2.adaptiveThreshold(sgray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, ADAPTIVE_WINSZ, 25)\n",
    "\n",
    "        if DEBUG_LEVEL >= 3:\n",
    "            debug_show(name, 0.1, 'thresholded', mask)\n",
    "\n",
    "        mask = cv2.dilate(mask, box(9, 1))\n",
    "\n",
    "        if DEBUG_LEVEL >= 3:\n",
    "            debug_show(name, 0.2, 'dilated', mask)\n",
    "\n",
    "        mask = cv2.erode(mask, box(1, 3))\n",
    "\n",
    "        if DEBUG_LEVEL >= 3:\n",
    "            debug_show(name, 0.3, 'eroded', mask)\n",
    "\n",
    "    else:\n",
    "\n",
    "        mask = cv2.adaptiveThreshold(sgray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                     cv2.THRESH_BINARY_INV,\n",
    "                                     ADAPTIVE_WINSZ,\n",
    "                                     7)\n",
    "                    \n",
    "        # mask = cv2.adaptiveThreshold(sgray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 4)\n",
    "\n",
    "        if DEBUG_LEVEL >= 3:\n",
    "            debug_show(name, 0.4, 'thresholded', mask)\n",
    "\n",
    "        mask = cv2.erode(mask, box(3, 1), iterations=3)\n",
    "\n",
    "        if DEBUG_LEVEL >= 3:\n",
    "            debug_show(name, 0.5, 'eroded', mask)\n",
    "\n",
    "        mask = cv2.dilate(mask, box(8, 2))\n",
    "\n",
    "        if DEBUG_LEVEL >= 3:\n",
    "            debug_show(name, 0.6, 'dilated', mask)\n",
    "\n",
    "    return np.minimum(mask, pagemask)\n",
    "\n",
    "\n",
    "def interval_measure_overlap(int_a, int_b):\n",
    "    return min(int_a[1], int_b[1]) - max(int_a[0], int_b[0])\n",
    "\n",
    "\n",
    "def angle_dist(angle_b, angle_a):\n",
    "\n",
    "    diff = angle_b - angle_a\n",
    "\n",
    "    while diff > np.pi:\n",
    "        diff -= 2*np.pi\n",
    "\n",
    "    while diff < -np.pi:\n",
    "        diff += 2*np.pi\n",
    "\n",
    "    return np.abs(diff)\n",
    "\n",
    "\n",
    "def blob_mean_and_tangent(contour):\n",
    "\n",
    "    moments = cv2.moments(contour)\n",
    "\n",
    "    area = moments['m00']\n",
    "    \n",
    "    if area == 0:\n",
    "        return np.array([0,0]), np.array([0,0])\n",
    "\n",
    "    mean_x = old_div(moments['m10'], area)\n",
    "    mean_y = old_div(moments['m01'], area)\n",
    "\n",
    "    moments_matrix = old_div(np.array([\n",
    "        [moments['mu20'], moments['mu11']],\n",
    "        [moments['mu11'], moments['mu02']]\n",
    "    ]), area)\n",
    "\n",
    "    _, svd_u, _ = cv2.SVDecomp(moments_matrix)\n",
    "\n",
    "    center = np.array([mean_x, mean_y])\n",
    "    tangent = svd_u[:, 0].flatten().copy()\n",
    "\n",
    "    return center, tangent\n",
    "\n",
    "\n",
    "class ContourInfo(object):\n",
    "\n",
    "    def __init__(self, contour, rect, mask):\n",
    "\n",
    "        self.contour = contour\n",
    "        self.rect = rect\n",
    "        self.mask = mask\n",
    "\n",
    "        self.center, self.tangent = blob_mean_and_tangent(contour)\n",
    "\n",
    "        self.angle = np.arctan2(self.tangent[1], self.tangent[0])\n",
    "\n",
    "        clx = [self.proj_x(point) for point in contour]\n",
    "\n",
    "        lxmin = min(clx)\n",
    "        lxmax = max(clx)\n",
    "\n",
    "        self.local_xrng = (lxmin, lxmax)\n",
    "\n",
    "        self.point0 = self.center + self.tangent * lxmin\n",
    "        self.point1 = self.center + self.tangent * lxmax\n",
    "\n",
    "        self.pred = None\n",
    "        self.succ = None\n",
    "\n",
    "    def proj_x(self, point):\n",
    "        return np.dot(self.tangent, point.flatten()-self.center)\n",
    "\n",
    "    def local_overlap(self, other):\n",
    "        xmin = self.proj_x(other.point0)\n",
    "        xmax = self.proj_x(other.point1)\n",
    "        return interval_measure_overlap(self.local_xrng, (xmin, xmax))\n",
    "\n",
    "\n",
    "def generate_candidate_edge(cinfo_a, cinfo_b):\n",
    "\n",
    "    # we want a left of b (so a's successor will be b and b's\n",
    "    # predecessor will be a) make sure right endpoint of b is to the\n",
    "    # right of left endpoint of a.\n",
    "    if cinfo_a.point0[0] > cinfo_b.point1[0]:\n",
    "        tmp = cinfo_a\n",
    "        cinfo_a = cinfo_b\n",
    "        cinfo_b = tmp\n",
    "\n",
    "    x_overlap_a = cinfo_a.local_overlap(cinfo_b)\n",
    "    x_overlap_b = cinfo_b.local_overlap(cinfo_a)\n",
    "\n",
    "    overall_tangent = cinfo_b.center - cinfo_a.center\n",
    "    overall_angle = np.arctan2(overall_tangent[1], overall_tangent[0])\n",
    "\n",
    "    delta_angle = old_div(max(angle_dist(cinfo_a.angle, overall_angle),\n",
    "                      angle_dist(cinfo_b.angle, overall_angle)) * 180,np.pi)\n",
    "\n",
    "    # we want the largest overlap in x to be small\n",
    "    x_overlap = max(x_overlap_a, x_overlap_b)\n",
    "\n",
    "    dist = np.linalg.norm(cinfo_b.point0 - cinfo_a.point1)\n",
    "\n",
    "    if (dist > EDGE_MAX_LENGTH or\n",
    "            x_overlap > EDGE_MAX_OVERLAP or\n",
    "            delta_angle > EDGE_MAX_ANGLE):\n",
    "        return None\n",
    "    else:\n",
    "        score = dist + delta_angle*EDGE_ANGLE_COST\n",
    "        return (score, cinfo_a, cinfo_b)\n",
    "\n",
    "\n",
    "def make_tight_mask(contour, xmin, ymin, width, height):\n",
    "\n",
    "    tight_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    tight_contour = contour - np.array((xmin, ymin)).reshape((-1, 1, 2))\n",
    "\n",
    "    cv2.drawContours(tight_mask, [tight_contour], 0,\n",
    "                     (1, 1, 1), -1)\n",
    "\n",
    "    return tight_mask\n",
    "\n",
    "\n",
    "def get_contours(name, small, pagemask, masktype):\n",
    "\n",
    "    mask = get_mask(name, small, pagemask, masktype)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL,\n",
    "                                   cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    contours_out = []\n",
    "\n",
    "    for contour in contours:\n",
    "\n",
    "        rect = cv2.boundingRect(contour)\n",
    "        xmin, ymin, width, height = rect\n",
    "\n",
    "        if (width < TEXT_MIN_WIDTH or\n",
    "                height < TEXT_MIN_HEIGHT or\n",
    "                width < TEXT_MIN_ASPECT*height):\n",
    "            continue\n",
    "\n",
    "        tight_mask = make_tight_mask(contour, xmin, ymin, width, height)\n",
    "\n",
    "        if tight_mask.sum(axis=0).max() > TEXT_MAX_THICKNESS:\n",
    "            continue\n",
    "\n",
    "        contours_out.append(ContourInfo(contour, rect, tight_mask))\n",
    "\n",
    "    if DEBUG_LEVEL >= 2:\n",
    "        visualize_contours(name, small, contours_out)\n",
    "\n",
    "    return contours_out\n",
    "\n",
    "\n",
    "def assemble_spans(name, small, pagemask, cinfo_list):\n",
    "\n",
    "    # sort list\n",
    "    cinfo_list = sorted(cinfo_list, key=lambda cinfo: cinfo.rect[1])\n",
    "\n",
    "    # generate all candidate edges\n",
    "    candidate_edges = []\n",
    "\n",
    "    for i, cinfo_i in enumerate(cinfo_list):\n",
    "        for j in range(i):\n",
    "            # note e is of the form (score, left_cinfo, right_cinfo)\n",
    "            edge = generate_candidate_edge(cinfo_i, cinfo_list[j])\n",
    "            if edge is not None:\n",
    "                candidate_edges.append(edge)\n",
    "\n",
    "    # sort candidate edges by score (lower is better)\n",
    "    candidate_edges.sort()\n",
    "\n",
    "    # for each candidate edge\n",
    "    for _, cinfo_a, cinfo_b in candidate_edges:\n",
    "        # if left and right are unassigned, join them\n",
    "        if cinfo_a.succ is None and cinfo_b.pred is None:\n",
    "            cinfo_a.succ = cinfo_b\n",
    "            cinfo_b.pred = cinfo_a\n",
    "\n",
    "    # generate list of spans as output\n",
    "    spans = []\n",
    "\n",
    "    # until we have removed everything from the list\n",
    "    while cinfo_list:\n",
    "\n",
    "        # get the first on the list\n",
    "        cinfo = cinfo_list[0]\n",
    "\n",
    "        # keep following predecessors until none exists\n",
    "        while cinfo.pred:\n",
    "            cinfo = cinfo.pred\n",
    "\n",
    "        # start a new span\n",
    "        cur_span = []\n",
    "\n",
    "        width = 0.0\n",
    "\n",
    "        # follow successors til end of span\n",
    "        while cinfo:\n",
    "            # remove from list (sadly making this loop *also* O(n^2)\n",
    "            cinfo_list.remove(cinfo)\n",
    "            # add to span\n",
    "            cur_span.append(cinfo)\n",
    "            width += cinfo.local_xrng[1] - cinfo.local_xrng[0]\n",
    "            # set successor\n",
    "            cinfo = cinfo.succ\n",
    "\n",
    "        # add if long enough\n",
    "        if width > SPAN_MIN_WIDTH:\n",
    "            spans.append(cur_span)\n",
    "\n",
    "    if DEBUG_LEVEL >= 2:\n",
    "        visualize_spans(name, small, pagemask, spans)\n",
    "\n",
    "    return spans\n",
    "\n",
    "\n",
    "def sample_spans(shape, spans):\n",
    "\n",
    "    span_points = []\n",
    "\n",
    "    for span in spans:\n",
    "\n",
    "        contour_points = []\n",
    "\n",
    "        for cinfo in span:\n",
    "\n",
    "            yvals = np.arange(cinfo.mask.shape[0]).reshape((-1, 1))\n",
    "            totals = (yvals * cinfo.mask).sum(axis=0)\n",
    "            means = old_div(totals, cinfo.mask.sum(axis=0))\n",
    "\n",
    "            xmin, ymin = cinfo.rect[:2]\n",
    "\n",
    "            step = SPAN_PX_PER_STEP\n",
    "            start = old_div(((len(means)-1) % step), 2)\n",
    "\n",
    "            contour_points += [(x+xmin, means[x]+ymin)\n",
    "                               for x in range(start, len(means), step)]\n",
    "\n",
    "        contour_points = np.array(contour_points,\n",
    "                                  dtype=np.float32).reshape((-1, 1, 2))\n",
    "\n",
    "        contour_points = pix2norm(shape, contour_points)\n",
    "\n",
    "        span_points.append(contour_points)\n",
    "\n",
    "    return span_points\n",
    "\n",
    "\n",
    "def keypoints_from_samples(name, small, pagemask, page_outline,\n",
    "                           span_points):\n",
    "\n",
    "    all_evecs = np.array([[0.0, 0.0]])\n",
    "    all_weights = 0\n",
    "\n",
    "    for points in span_points:\n",
    "\n",
    "        _, evec = cv2.PCACompute(points.reshape((-1, 2)),\n",
    "                                 None, maxComponents=1)\n",
    "\n",
    "        weight = np.linalg.norm(points[-1] - points[0])\n",
    "\n",
    "        all_evecs += evec * weight\n",
    "        all_weights += weight\n",
    "\n",
    "    evec = old_div(all_evecs, all_weights)\n",
    "\n",
    "    x_dir = evec.flatten()\n",
    "\n",
    "    if x_dir[0] < 0:\n",
    "        x_dir = -x_dir\n",
    "\n",
    "    y_dir = np.array([-x_dir[1], x_dir[0]])\n",
    "\n",
    "    pagecoords = cv2.convexHull(page_outline)\n",
    "    pagecoords = pix2norm(pagemask.shape, pagecoords.reshape((-1, 1, 2)))\n",
    "    pagecoords = pagecoords.reshape((-1, 2))\n",
    "\n",
    "    px_coords = np.dot(pagecoords, x_dir)\n",
    "    py_coords = np.dot(pagecoords, y_dir)\n",
    "\n",
    "    px0 = px_coords.min()\n",
    "    px1 = px_coords.max()\n",
    "\n",
    "    py0 = py_coords.min()\n",
    "    py1 = py_coords.max()\n",
    "\n",
    "    p00 = px0 * x_dir + py0 * y_dir\n",
    "    p10 = px1 * x_dir + py0 * y_dir\n",
    "    p11 = px1 * x_dir + py1 * y_dir\n",
    "    p01 = px0 * x_dir + py1 * y_dir\n",
    "\n",
    "    corners = np.vstack((p00, p10, p11, p01)).reshape((-1, 1, 2))\n",
    "\n",
    "    ycoords = []\n",
    "    xcoords = []\n",
    "\n",
    "    for points in span_points:\n",
    "        pts = points.reshape((-1, 2))\n",
    "        px_coords = np.dot(pts, x_dir)\n",
    "        py_coords = np.dot(pts, y_dir)\n",
    "        ycoords.append(py_coords.mean() - py0)\n",
    "        xcoords.append(px_coords - px0)\n",
    "\n",
    "    if DEBUG_LEVEL >= 2:\n",
    "        visualize_span_points(name, small, span_points, corners)\n",
    "\n",
    "    return corners, np.array(ycoords), xcoords\n",
    "\n",
    "\n",
    "def visualize_contours(name, small, cinfo_list):\n",
    "\n",
    "    regions = np.zeros_like(small)\n",
    "\n",
    "    for j, cinfo in enumerate(cinfo_list):\n",
    "\n",
    "        cv2.drawContours(regions, [cinfo.contour], 0,\n",
    "                         CCOLORS[j % len(CCOLORS)], -1)\n",
    "\n",
    "    mask = (regions.max(axis=2) != 0)\n",
    "\n",
    "    display = small.copy()\n",
    "    display[mask] = (old_div(display[mask],2)) + (old_div(regions[mask],2))\n",
    "\n",
    "    for j, cinfo in enumerate(cinfo_list):\n",
    "        color = CCOLORS[j % len(CCOLORS)]\n",
    "        color = tuple([old_div(c,4) for c in color])\n",
    "\n",
    "        cv2.circle(display, fltp(cinfo.center), 3,\n",
    "                   (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.line(display, fltp(cinfo.point0), fltp(cinfo.point1),\n",
    "                 (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    debug_show(name, 1, 'contours', display)\n",
    "\n",
    "\n",
    "def visualize_spans(name, small, pagemask, spans):\n",
    "\n",
    "    regions = np.zeros_like(small)\n",
    "\n",
    "    for i, span in enumerate(spans):\n",
    "        contours = [cinfo.contour for cinfo in span]\n",
    "        cv2.drawContours(regions, contours, -1,\n",
    "                         CCOLORS[i*3 % len(CCOLORS)], -1)\n",
    "\n",
    "    mask = (regions.max(axis=2) != 0)\n",
    "\n",
    "    display = small.copy()\n",
    "    display[mask] = (old_div(display[mask],2)) + (old_div(regions[mask],2))\n",
    "    display[pagemask == 0] //= 4\n",
    "\n",
    "    debug_show(name, 2, 'spans', display)\n",
    "\n",
    "\n",
    "def visualize_span_points(name, small, span_points, corners):\n",
    "\n",
    "    display = small.copy()\n",
    "\n",
    "    for i, points in enumerate(span_points):\n",
    "\n",
    "        points = norm2pix(small.shape, points, False)\n",
    "\n",
    "        mean, small_evec = cv2.PCACompute(points.reshape((-1, 2)),\n",
    "                                          None,\n",
    "                                          maxComponents=1)\n",
    "\n",
    "        dps = np.dot(points.reshape((-1, 2)), small_evec.reshape((2, 1)))\n",
    "        dpm = np.dot(mean.flatten(), small_evec.flatten())\n",
    "\n",
    "        point0 = mean + small_evec * (dps.min()-dpm)\n",
    "        point1 = mean + small_evec * (dps.max()-dpm)\n",
    "\n",
    "        for point in points:\n",
    "            cv2.circle(display, fltp(point), 3,\n",
    "                       CCOLORS[i % len(CCOLORS)], -1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.line(display, fltp(point0), fltp(point1),\n",
    "                 (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.polylines(display, [norm2pix(small.shape, corners, True)],\n",
    "                  True, (255, 255, 255))\n",
    "\n",
    "    debug_show(name, 3, 'span points', display)\n",
    "\n",
    "\n",
    "def imgsize(img):\n",
    "    height, width = img.shape[:2]\n",
    "    return '{}x{}'.format(width, height)\n",
    "\n",
    "\n",
    "def make_keypoint_index(span_counts):\n",
    "\n",
    "    nspans = len(span_counts)\n",
    "    npts = sum(span_counts)\n",
    "    keypoint_index = np.zeros((npts+1, 2), dtype=int)\n",
    "    start = 1\n",
    "\n",
    "    for i, count in enumerate(span_counts):\n",
    "        end = start + count\n",
    "        keypoint_index[start:start+end, 1] = 8+i\n",
    "        start = end\n",
    "\n",
    "    keypoint_index[1:, 0] = np.arange(npts) + 8 + nspans\n",
    "\n",
    "    return keypoint_index\n",
    "\n",
    "\n",
    "def optimize_params(name, small, dstpoints, span_counts, params):\n",
    "\n",
    "    keypoint_index = make_keypoint_index(span_counts)\n",
    "\n",
    "    def objective(pvec):\n",
    "        ppts = project_keypoints(pvec, keypoint_index)\n",
    "        return np.sum((dstpoints - ppts)**2)\n",
    "\n",
    "    print('  initial objective is', objective(params))\n",
    "\n",
    "    if DEBUG_LEVEL >= 1:\n",
    "        projpts = project_keypoints(params, keypoint_index)\n",
    "        display = draw_correspondences(small, dstpoints, projpts)\n",
    "        debug_show(name, 4, 'keypoints before', display)\n",
    "\n",
    "    print('  optimizing', len(params), 'parameters...')\n",
    "    start = datetime.datetime.now()\n",
    "    res = scipy.optimize.minimize(objective, params,\n",
    "                                  method='Powell')\n",
    "    end = datetime.datetime.now()\n",
    "    print('  optimization took', round((end-start).total_seconds(), 2), 'sec.')\n",
    "    print('  final objective is', res.fun)\n",
    "    params = res.x\n",
    "\n",
    "    if DEBUG_LEVEL >= 1:\n",
    "        projpts = project_keypoints(params, keypoint_index)\n",
    "        display = draw_correspondences(small, dstpoints, projpts)\n",
    "        debug_show(name, 5, 'keypoints after', display)\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_page_dims(corners, rough_dims, params):\n",
    "\n",
    "    dst_br = corners[2].flatten()\n",
    "\n",
    "    dims = np.array(rough_dims)\n",
    "\n",
    "    def objective(dims):\n",
    "        proj_br = project_xy(dims, params)\n",
    "        return np.sum((dst_br - proj_br.flatten())**2)\n",
    "\n",
    "    res = scipy.optimize.minimize(objective, dims, method='Powell')\n",
    "    dims = res.x\n",
    "\n",
    "    print('  got page dims', dims[0], 'x', dims[1])\n",
    "\n",
    "    return dims\n",
    "\n",
    "\n",
    "def remap_image(name, img, small, page_dims, params, output_path):\n",
    "\n",
    "    height = 0.5 * page_dims[1] * OUTPUT_ZOOM * img.shape[0]\n",
    "    height = round_nearest_multiple(height, REMAP_DECIMATE)\n",
    "\n",
    "    width = round_nearest_multiple(old_div(height * page_dims[0], page_dims[1]),\n",
    "                                   REMAP_DECIMATE)\n",
    "\n",
    "    print('  output will be {}x{}'.format(width, height))\n",
    "\n",
    "    height_small = old_div(height, REMAP_DECIMATE)\n",
    "    width_small = old_div(width, REMAP_DECIMATE)\n",
    "\n",
    "    page_x_range = np.linspace(0, page_dims[0], width_small)\n",
    "    page_y_range = np.linspace(0, page_dims[1], height_small)\n",
    "\n",
    "    page_x_coords, page_y_coords = np.meshgrid(page_x_range, page_y_range)\n",
    "\n",
    "    page_xy_coords = np.hstack((page_x_coords.flatten().reshape((-1, 1)),\n",
    "                                page_y_coords.flatten().reshape((-1, 1))))\n",
    "\n",
    "    page_xy_coords = page_xy_coords.astype(np.float32)\n",
    "\n",
    "    image_points = project_xy(page_xy_coords, params)\n",
    "    image_points = norm2pix(img.shape, image_points, False)\n",
    "\n",
    "    image_x_coords = image_points[:, 0, 0].reshape(page_x_coords.shape)\n",
    "    image_y_coords = image_points[:, 0, 1].reshape(page_y_coords.shape)\n",
    "\n",
    "    image_x_coords = cv2.resize(image_x_coords, (width, height),\n",
    "                                interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    image_y_coords = cv2.resize(image_y_coords, (width, height),\n",
    "                                interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    remapped = cv2.remap(img_gray, image_x_coords, image_y_coords,\n",
    "                         cv2.INTER_CUBIC,\n",
    "                         None, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # thresh = cv2.adaptiveThreshold(remapped, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, ADAPTIVE_WINSZ, 25)\n",
    "    thresh = cv2.adaptiveThreshold(remapped, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 4)\n",
    "\n",
    "    pil_image = Image.fromarray(thresh)\n",
    "    pil_image = pil_image.convert('1')\n",
    "\n",
    "    threshfile = name + '_thresh.png'\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    output_threshfile = os.path.join(output_path, threshfile)\n",
    "    pil_image.save(output_threshfile, dpi=(OUTPUT_DPI, OUTPUT_DPI))\n",
    "\n",
    "    if DEBUG_LEVEL >= 1:\n",
    "        height = small.shape[0]\n",
    "        width = int(round(height * float(thresh.shape[1])/thresh.shape[0]))\n",
    "        display = cv2.resize(thresh, (width, height),\n",
    "                             interpolation=cv2.INTER_AREA)\n",
    "        debug_show(name, 6, 'output', display)\n",
    "\n",
    "    return output_threshfile\n",
    "\n",
    "\n",
    "def page_dewarp(imgfile, output_path=\"threshes\"):\n",
    "\n",
    "    if DEBUG_LEVEL > 0 and DEBUG_OUTPUT != 'file':\n",
    "        cv2.namedWindow(WINDOW_NAME)\n",
    "\n",
    "    outfiles = []\n",
    "\n",
    "    img = cv2.imread(imgfile)\n",
    "    small = resize_to_screen(img)\n",
    "    basename = os.path.basename(imgfile)\n",
    "    name, _ = os.path.splitext(basename)\n",
    "\n",
    "    print('loaded', basename, 'with size', imgsize(img), end=' ')\n",
    "    print('and resized to', imgsize(small))\n",
    "\n",
    "    if DEBUG_LEVEL >= 3:\n",
    "        debug_show(name, 0.0, 'original', small)\n",
    "\n",
    "    pagemask, page_outline = get_page_extents(small)\n",
    "\n",
    "    cinfo_list = get_contours(name, small, pagemask, 'text')\n",
    "    spans = assemble_spans(name, small, pagemask, cinfo_list)\n",
    "\n",
    "    if len(spans) < 3:\n",
    "        print('  detecting lines because only', len(spans), 'text spans')\n",
    "        cinfo_list = get_contours(name, small, pagemask, 'line')\n",
    "        spans2 = assemble_spans(name, small, pagemask, cinfo_list)\n",
    "        if len(spans2) > len(spans):\n",
    "            spans = spans2\n",
    "\n",
    "    if len(spans) < 1:\n",
    "        print('skipping', name, 'because only', len(spans), 'spans')\n",
    "        return\n",
    "\n",
    "    span_points = sample_spans(small.shape, spans)\n",
    "\n",
    "    print('  got', len(spans), 'spans', end=' ')\n",
    "    print('with', sum([len(pts) for pts in span_points]), 'points.')\n",
    "\n",
    "    corners, ycoords, xcoords = keypoints_from_samples(name, small,\n",
    "                                                        pagemask,\n",
    "                                                        page_outline,\n",
    "                                                        span_points)\n",
    "\n",
    "    rough_dims, span_counts, params = get_default_params(corners,\n",
    "                                                            ycoords, xcoords)\n",
    "\n",
    "    dstpoints = np.vstack((corners[0].reshape((1, 1, 2)),) +\n",
    "                            tuple(span_points))\n",
    "\n",
    "    params = optimize_params(name, small,\n",
    "                                dstpoints,\n",
    "                                span_counts, params)\n",
    "\n",
    "    page_dims = get_page_dims(corners, rough_dims, params)\n",
    "\n",
    "    outfile = remap_image(name, img, small, page_dims, params, output_path)\n",
    "\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded not_bad_at_coding.jpg with size 1280x794 and resized to 640x397\n",
      "  got 12 spans with 147 points.\n",
      "  initial objective is 0.000983501056451414\n",
      "  optimizing 167 parameters...\n",
      "  optimization took 6.84 sec.\n",
      "  final objective is 0.00025956530201118067\n",
      "  got page dims 1.7380212152528396 x 1.1293530256691877\n",
      "  output will be 704x448\n",
      "threshes/not_bad_at_coding_thresh.png <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "img_file = \"Sample_images/not_bad_at_coding.jpg\"\n",
    "outfile = page_dewarp(img_file)\n",
    "print(outfile, type(outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated CTPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from nets import model_train as model\n",
    "from utils.rpn_msr.proposal_layer import proposal_layer\n",
    "from utils.text_connector.detectors import TextDetector\n",
    "textdetector = TextDetector(DETECT_MODE='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'text-detection-ctpn/data/demo/'\n",
    "output_path = 'text-detection-ctpn/data/res/'\n",
    "gpu = '0'\n",
    "checkpoint_path = 'text-detection-ctpn/checkpoints_mlt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    img_size = img.shape\n",
    "    im_size_min = np.min(img_size[0:2])\n",
    "    im_size_max = np.max(img_size[0:2])\n",
    "\n",
    "    im_scale = float(600) / float(im_size_min)\n",
    "    if np.round(im_scale * im_size_max) > 1200:\n",
    "        im_scale = float(1200) / float(im_size_max)\n",
    "    new_h = int(img_size[0] * im_scale)\n",
    "    new_w = int(img_size[1] * im_scale)\n",
    "\n",
    "    new_h = new_h if new_h // 16 == 0 else (new_h // 16 + 1) * 16\n",
    "    new_w = new_w if new_w // 16 == 0 else (new_w // 16 + 1) * 16\n",
    "\n",
    "    re_im = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "    return re_im, (new_h / img_size[0], new_w / img_size[1])\n",
    "\n",
    "\n",
    "def ctpn(imgfile):\n",
    "    if imgfile.strip() == \"\":\n",
    "        raise IOError\n",
    "    #if os.path.exists(output_path):\n",
    "        #shutil.rmtree(output_path)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # INFO and WARNING messages are not printed\n",
    "    \n",
    "    output_img_file, txt_file = \"\", \"\"\n",
    "\n",
    "    try:\n",
    "        with tf.get_default_graph().as_default():\n",
    "            input_image = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='input_image')\n",
    "            input_im_info = tf.placeholder(tf.float32, shape=[None, 3], name='input_im_info')\n",
    "\n",
    "            global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "            bbox_pred, cls_pred, cls_prob = model.model(input_image)\n",
    "\n",
    "            variable_averages = tf.train.ExponentialMovingAverage(0.997, global_step)\n",
    "            saver = tf.train.Saver(variable_averages.variables_to_restore())\n",
    "\n",
    "            with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "                ckpt_state = tf.train.get_checkpoint_state(checkpoint_path)\n",
    "                model_path = os.path.join(checkpoint_path, os.path.basename(ckpt_state.model_checkpoint_path))\n",
    "                print('Restore from {}'.format(model_path))\n",
    "                saver.restore(sess, model_path)\n",
    "\n",
    "                start = time.time()\n",
    "                try:\n",
    "                    im = cv2.imread(imgfile)[:, :, ::-1]\n",
    "                except:\n",
    "                    print(\"Error reading image {}!\".format(imgfile))\n",
    "                    tf.reset_default_graph()\n",
    "                    raise IOError\n",
    "\n",
    "                img, (rh, rw) = resize_image(im)\n",
    "                h, w, c = img.shape\n",
    "                im_info = np.array([h, w, c]).reshape([1, 3])\n",
    "                bbox_pred_val, cls_prob_val = sess.run([bbox_pred, cls_prob],\n",
    "                                                    feed_dict={input_image: [img],\n",
    "                                                            input_im_info: im_info})\n",
    "\n",
    "                textsegs, _ = proposal_layer(cls_prob_val, bbox_pred_val, im_info)\n",
    "                scores = textsegs[:, 0]\n",
    "                textsegs = textsegs[:, 1:5]\n",
    "\n",
    "                textdetector = TextDetector(DETECT_MODE='O')\n",
    "                boxes = textdetector.detect(textsegs, scores[:, np.newaxis], img.shape[:2])\n",
    "                boxes = np.array(boxes, dtype=np.int)\n",
    "\n",
    "                cost_time = (time.time() - start)\n",
    "                print(\"cost time: {:.2f}s\".format(cost_time))\n",
    "\n",
    "                for i, box in enumerate(boxes):\n",
    "                    cv2.polylines(img, [box[:8].astype(np.int32).reshape((-1, 1, 2))], True, color=(0, 255, 0),\n",
    "                                thickness=2)\n",
    "                img = cv2.resize(img, None, None, fx=1.0 / rh, fy=1.0 / rw, interpolation=cv2.INTER_LINEAR)\n",
    "                output_img_file = os.path.join(output_path, os.path.basename(imgfile))\n",
    "                cv2.imwrite(output_img_file, img[:, :, ::-1])\n",
    "\n",
    "                txt_file = os.path.join(output_path, os.path.splitext(os.path.basename(imgfile))[0]) + \".txt\"\n",
    "                with open(txt_file, \"w\") as f:\n",
    "                    for i, box in enumerate(boxes):\n",
    "                        line = \",\".join(str(box[k]) for k in range(8))\n",
    "                        line += \",\" + str(scores[i]) + \"\\r\\n\"\n",
    "                        f.writelines(line)\n",
    "    except:\n",
    "        tf.reset_default_graph()\n",
    "        traceback.print_exc()\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    return output_img_file, txt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore from text-detection-ctpn/checkpoints_mlt/ctpn_50000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from text-detection-ctpn/checkpoints_mlt/ctpn_50000.ckpt\n",
      "cost time: 2.40s\n"
     ]
    }
   ],
   "source": [
    "fi, ftxt = ctpn(\"text-detection-ctpn/data/demo/hadalabo_thresh.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The OCR Shit\n",
    "This part is everything after dewarp and ctpn, taken from Hien's work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(txt):\n",
    "    annotation = txt\n",
    "    with open(annotation, \"r\") as file1:\n",
    "        bounding_boxes = file1.read()\n",
    "        \n",
    "    bounding_boxes = bounding_boxes.split('\\n')[:-1]\n",
    "    boxes = [i.split(',')[:-1] for i in bounding_boxes]\n",
    "\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        new_box = []\n",
    "        for i, each in enumerate(box):\n",
    "            num = int(each)\n",
    "            if i in [0, 1, 3, 6]:\n",
    "                num -= 3\n",
    "            else: \n",
    "                num += 3\n",
    "            new_box.append(num)\n",
    "        new_boxes.append(new_box)\n",
    "    new_boxes.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return new_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    text = string.replace('INACTIVE INGREDIENTS:', '') # added\n",
    "    text = text.replace('ACTIVE INGREDIENTS:', '') # added\n",
    "    text = text.split(':')[1]\n",
    "    \n",
    "    pattern = \"[\\|\\*\\_\\'\\{}&]\".format('\"')\n",
    "    regex = re.compile('\\\\\\S+')\n",
    "    \n",
    "    text = re.sub(pattern, \"\", text)\n",
    "    text = re.sub(\",, \", \", \", text)\n",
    "    text = re.sub(regex, \" \", text)\n",
    "    text = re.sub('\\.', \" \", text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    text_wo_sw = [w for w in text_tokens if not w in stopwords.words()]\n",
    "    text = ' '.join(text_wo_sw)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def string_to_list(text):\n",
    "    pattern = \"[\\|\\*\\_\\'\\{}]\".format('\"')\n",
    "    text = re.sub(pattern, \"\", text)\n",
    "    split = [remove_water(x) for x in re.split(\"[,.]\", text)]\n",
    "    \n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_water(string):\n",
    "    water = ['WATER (AQUA)', 'AQUA', 'EAU', 'AQUA/WATER/EAU', 'AQUA / WATER / EAU', \n",
    "             'PURIFIED WATER', 'DISTILLED WATER', 'D.I. WATER', 'AQUA (WATER)', 'AQUA (PURIFIED)']\n",
    "    text = string.upper()\n",
    "    if text in water:\n",
    "        text = 'WATER'\n",
    "    text = text.strip('  ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_line(img_path, box):\n",
    "    img = cv2.imread(img_path)\n",
    "    img, (rh, rw) = resize_image(img)\n",
    "    # points for test.jpg\n",
    "    cnt = np.array([\n",
    "            [[box[0], box[1]]],\n",
    "            [[box[2], box[3]]],\n",
    "            [[box[4], box[5]]],\n",
    "            [[box[6], box[7]]]\n",
    "        ])\n",
    "    # print(\"shape of cnt: {}\".format(cnt.shape))\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "#     print(\"rect: {}\".format(rect))\n",
    "\n",
    "    # the order of the box points: bottom left, top left, top right,\n",
    "    # bottom right\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    # print(\"bounding box: {}\".format(box))\n",
    "    cv2.drawContours(img, [box], 0, (0, 0, 255), 2)\n",
    "\n",
    "    # get width and height of the detected rectangle\n",
    "    width = int(rect[1][0])\n",
    "    height = int(rect[1][1])\n",
    "    angle = rect[2]\n",
    "\n",
    "    src_pts = box.astype(\"float32\")\n",
    "    # coordinate of the points in box points after the rectangle has been\n",
    "    # straightened\n",
    "    dst_pts = np.array([[0, height+2],\n",
    "                        [0, 0],\n",
    "                        [width, 0],\n",
    "                        [width, height+2]], dtype=\"float32\")\n",
    "\n",
    "    # the perspective transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "\n",
    "    # directly warp the rotated rectangle to get the straightened rectangle\n",
    "    warped = cv2.warpPerspective(img, M, (width, height))\n",
    "\n",
    "    # cv2.imwrite(\"crop_img.jpg\", warped)\n",
    "    \n",
    "    # cv2.waitKey(0)\n",
    "    if angle < -45:\n",
    "      warped = np.transpose(warped,(1,0,2))\n",
    "      warped = warped[::-1]\n",
    "\n",
    "#     cv2.imshow('croped', warped)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(img, oem=3, psm=6):\n",
    "    \"\"\"\n",
    "    @param img: The image to be OCR'd\n",
    "    @param oem: for specifying the type of Tesseract engine( default=1 for LSTM OCR Engine)\n",
    "    \"\"\"\n",
    "    config = ('-l eng --oem {oem} --psm {psm}'.format(oem=oem,psm=psm))\n",
    "    # config = ('-l eng --tessdata-dir \"/usr/share/tesseract-ocr/tessdata\" --oem {oem} -- psm {psm}'.format(oem=oem,psm=psm))\n",
    "\n",
    "    try:\n",
    "#         img = Image.fromarray(img)\n",
    "        text = pytesseract.image_to_string(img, config=config)\n",
    "\n",
    "        return text\n",
    "    except:\n",
    "        \n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.GaussianBlur(image, (5,5), 0)\n",
    "\n",
    "# thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 4)\n",
    "\n",
    "def preprocess_for_ocr(img, enhance=1):\n",
    "    \"\"\"\n",
    "    @param img: image to which the pre-processing steps being applied\n",
    "    \"\"\"\n",
    "    if enhance > 1:\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        contrast = ImageEnhance.Contrast(img)\n",
    "\n",
    "        img = contrast.enhance(enhance)\n",
    "\n",
    "        img = np.asarray(img)\n",
    "    \n",
    "    \n",
    "    gray = get_grayscale(img)\n",
    "    blur = remove_noise(gray)\n",
    "    res = thresholding(blur)\n",
    "\n",
    "    img = cv2.cvtColor(res, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzydict\n",
    "\n",
    "from fuzzywuzzy import fuzz \n",
    "\n",
    "class FuzzyDict(dict):\n",
    "    \"Provides a dictionary that performs fuzzy lookup\"\n",
    "    def __init__(self, items = None, cutoff = .6):\n",
    "        \"\"\"Construct a new FuzzyDict instance\n",
    "\n",
    "        items is an dictionary to copy items from (optional)\n",
    "        cutoff is the match ratio below which mathes should not be considered\n",
    "        cutoff needs to be a float between 0 and 1 (where zero is no match\n",
    "        and 1 is a perfect match)\"\"\"\n",
    "        super(FuzzyDict, self).__init__()\n",
    "\n",
    "        if items:\n",
    "            self.update(items)\n",
    "        self.cutoff =  cutoff\n",
    "\n",
    "        # short wrapper around some super (dict) methods\n",
    "        self._dict_contains = lambda key: \\\n",
    "            super(FuzzyDict,self).__contains__(key)\n",
    "\n",
    "        self._dict_getitem = lambda key: \\\n",
    "            super(FuzzyDict,self).__getitem__(key)\n",
    "\n",
    "    def _search(self, lookfor, stop_on_first = False):\n",
    "        \"\"\"Returns the value whose key best matches lookfor\n",
    "\n",
    "        if stop_on_first is True then the method returns as soon\n",
    "        as it finds the first item\n",
    "        \"\"\"\n",
    "\n",
    "        # if the item is in the dictionary then just return it\n",
    "        if self._dict_contains(lookfor):\n",
    "            return True, lookfor, self._dict_getitem(lookfor), 1\n",
    "\n",
    "        # set up the fuzzy matching tool\n",
    "        #ratio_calc = difflib.SequenceMatcher()\n",
    "        #ratio_calc.set_seq1(lookfor)\n",
    "\n",
    "        # test each key in the dictionary\n",
    "        best_ratio = 0\n",
    "        best_match = None\n",
    "        best_key = None\n",
    "        for key in self:\n",
    "\n",
    "            # if the current key is not a string\n",
    "            # then we just skip it\n",
    "            if not isinstance(key, str):\n",
    "                continue\n",
    "\n",
    "            # we get an error here if the item to look for is not a\n",
    "            # string - if it cannot be fuzzy matched and we are here\n",
    "            # this it is defintely not in the dictionary\n",
    "            try:\n",
    "            # calculate the match value\n",
    "                ratio = fuzz.ratio(lookfor, key)/100\n",
    "            except TypeError:\n",
    "                break\n",
    "\n",
    "            # if this is the best ratio so far - save it and the value\n",
    "            if ratio > best_ratio:\n",
    "                best_ratio = ratio\n",
    "                best_key = key\n",
    "                best_match = self._dict_getitem(key)\n",
    "\n",
    "            if stop_on_first and ratio >= self.cutoff:\n",
    "                break\n",
    "\n",
    "        return (\n",
    "            best_ratio >= self.cutoff,\n",
    "            best_key,\n",
    "            best_match,\n",
    "            best_ratio)\n",
    "\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        \"Overides Dictionary __contains__ to use fuzzy matching\"\n",
    "        if self._search(item, True)[0]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __getitem__(self, lookfor):\n",
    "        \"Overides Dictionary __getitem__ to use fuzzy matching\"\n",
    "        matched, key, item, ratio = self._search(lookfor)\n",
    "\n",
    "        if not matched:\n",
    "            raise KeyError(\n",
    "                \"'%s'. closest match: '%s' with ratio %.3f\"%\n",
    "                    (str(lookfor), str(key), ratio))\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match_ingredients(ing_list, fuzdict):\n",
    "    match_dict = {}\n",
    "    for ing in tqdm(ing_list):\n",
    "        if ing in match_dict.keys():\n",
    "            continue\n",
    "        upper_ing = ing.upper()\n",
    "        if fuzdict.__contains__(upper_ing):\n",
    "            match_dict[ing] = fuzdict[upper_ing]\n",
    "        else:\n",
    "            match_dict[ing] = 'unknown'\n",
    "    \n",
    "    return match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_english(df_inci, df_cosing):\n",
    "    rating_inci = {}\n",
    "    irritancy_inci = {}\n",
    "    comedogenicity_inci = {}\n",
    "    function_inci = {}\n",
    "    qfacts_inci = {}\n",
    "    desc_inci = {}\n",
    "    \n",
    "    desc_cosing = {}\n",
    "    function_cosing = {}\n",
    "    \n",
    "    for idx, row in tqdm(df_inci.iterrows()):\n",
    "        for name in row['ingredient_name'].split('/'):\n",
    "            chem_name = name.strip()\n",
    "            rating_inci[chem_name] = row['rating']\n",
    "            irritancy_inci[chem_name] = row['irritancy']\n",
    "            comedogenicity_inci[chem_name] = row['comedogenicity']\n",
    "            function_inci[chem_name] = row['functions']\n",
    "            qfacts_inci[chem_name] = row['quick_facts']\n",
    "            desc_inci[chem_name] = row['description']\n",
    "            \n",
    "    for idx, row in tqdm(df_cosing.iterrows()):\n",
    "        for name in row['ingredient_name'].split('/'):\n",
    "            desc_cosing[name] = row['description']\n",
    "            function_cosing[name] = row['functions']    \n",
    "    \n",
    "    return rating_inci, irritancy_inci, comedogenicity_inci, function_inci, qfacts_inci, desc_inci, desc_cosing, function_cosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_all_english(ingredient_list, match_dict_inci, match_dict_cosing,\n",
    "               df_inci, df_cosing, option=''):\n",
    "\n",
    "    with open('eng_rating_inci.pickle', 'rb') as handle:\n",
    "        rating_inci = pickle.load(handle)\n",
    "    with open('eng_irritancy_inci.pickle', 'rb') as handle:\n",
    "        irritancy_inci = pickle.load(handle)\n",
    "    with open('eng_comedogenicity_inci.pickle', 'rb') as handle:\n",
    "        comedogenicity_inci = pickle.load(handle)\n",
    "    with open('eng_function_inci.pickle', 'rb') as handle:\n",
    "        function_inci = pickle.load(handle)\n",
    "    with open('eng_qfacts_inci.pickle', 'rb') as handle:\n",
    "        qfacts_inci = pickle.load(handle)\n",
    "    with open('eng_desc_inci.pickle', 'rb') as handle:\n",
    "        desc_inci = pickle.load(handle)\n",
    "    with open('eng_desc_cosing.pickle', 'rb') as handle:\n",
    "        desc_cosing = pickle.load(handle)\n",
    "    with open('eng_function_cosing.pickle', 'rb') as handle:\n",
    "        function_cosing = pickle.load(handle)\n",
    "        \n",
    "    res = []\n",
    "    \n",
    "    for item in tqdm(ingredient_list):\n",
    "        \n",
    "        value = match_dict_inci[item]\n",
    "        if value == 'unknown':\n",
    "            key = match_dict_cosing.get(item, 'unknown')\n",
    "            rating = 'No rating'\n",
    "            irritancy = np.nan\n",
    "            comedogenicity = np.nan\n",
    "            functions = function_cosing.get(key, [])\n",
    "            quickfacts = np.nan\n",
    "            description = desc_cosing.get(key, [])        \n",
    "                \n",
    "        else:\n",
    "            key = match_dict_inci.get(item, 'unknown')\n",
    "            rating = rating_inci.get(key, 'No rating')\n",
    "            irritancy = irritancy_inci.get(key, np.nan)\n",
    "            comedogenicity = comedogenicity_inci.get(key, np.nan)\n",
    "            functions = function_inci.get(key, [])\n",
    "            quickfacts = qfacts_inci.get(key, [])\n",
    "            description = desc_inci.get(key, [])\n",
    "            \n",
    "        if key != 'unknown':    \n",
    "            if option == 'ingredient':\n",
    "                res.append(key)\n",
    "            elif option == 'rating':\n",
    "                res.append(rating)\n",
    "            elif option == 'irritancy':\n",
    "                res.append(irritancy)\n",
    "            elif option == 'comedogenicity':\n",
    "                res.append(comedogenicity)\n",
    "            elif option == 'functions':\n",
    "                res.append(functions)\n",
    "            elif option == 'quickfacts':\n",
    "                res.append(quickfacts)\n",
    "            elif option == 'description':\n",
    "                res.append(description)\n",
    "            else:\n",
    "                res.extend([[key, functions, rating, irritancy, comedogenicity, quickfacts, description]])\n",
    "            \n",
    "    df_res = pd.DataFrame(res, columns=['Ingredient_name', 'Functions', 'Rating', 'Irritancy',\n",
    "                                        'Comedogenicity', 'Quick_facts', 'Description'])\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_all_vietnamese(ingredient_list, match_dict_cmd, match_dict_cosing,\n",
    "               df_cmd, df_cosing, option=''):\n",
    "    \n",
    "    with open('vie_ratingscore_cmd.pickle', 'rb') as handle:\n",
    "        ratingscore_cmd = pickle.load(handle)\n",
    "    with open('vie_function_cmd.pickle', 'rb') as handle:\n",
    "        function_cmd = pickle.load(handle)\n",
    "    with open('vie_desc_cmd.pickle', 'rb') as handle:\n",
    "        desc_cmd = pickle.load(handle)    \n",
    "    \n",
    "    with open('eng_desc_cosing.pickle', 'rb') as handle:\n",
    "        desc_cosing = pickle.load(handle)\n",
    "    with open('eng_function_cosing.pickle', 'rb') as handle:\n",
    "        function_cosing = pickle.load(handle)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for item in tqdm(ingredient_list):\n",
    "        \n",
    "        value = match_dict_cmd[item]\n",
    "\n",
    "        if value == 'unknown':\n",
    "            key = match_dict_cosing.get(item, 'unknown')\n",
    "            rating_score = 'Chưa đánh giá'\n",
    "            functions = function_cosing.get(key, [])\n",
    "            description = desc_cosing.get(key, [])\n",
    "        else:\n",
    "            key = match_dict_cmd.get(item, 'unknown')\n",
    "            rating_score = ratingscore_cmd.get(key, np.nan)\n",
    "            functions = function_cmd.get(key, [])\n",
    "            description = desc_cmd.get(key, [])\n",
    "            \n",
    "        if key != 'unknown':             \n",
    "            if option == 'ingredient':\n",
    "                res.append(key)\n",
    "            elif option == 'rating_score':\n",
    "                res.append(rating_score)\n",
    "            elif option == 'functions':\n",
    "                res.append(functions)\n",
    "            elif option == 'description':\n",
    "                res.append(description)\n",
    "            else:\n",
    "                res.extend([[key, rating_score, functions, description]])\n",
    "            \n",
    "    df_res = pd.DataFrame(res, columns=['Ingredient_name', 'Rating_score', 'Functions', 'Description'])\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_everything(img_path, boundingtxt_file, inci_path, cmd_path, cosing_path, language, debug=False):\n",
    "    boxes = get_bounding_box(boundingtxt_file)\n",
    "    \n",
    "    # Preprocess image for OCR:\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # doing OCR\n",
    "    text = ''\n",
    "    for box in boxes:\n",
    "        cropped = crop_line(img_path, box)\n",
    "        string = ocr(cropped)\n",
    "        text = text + ' ' + str(string.strip('\\n').strip('\\x0c').strip())\n",
    "    \n",
    "    if debug:\n",
    "        print(text)\n",
    "    \n",
    "    # Cleaning result from OCR\n",
    "    text_result = clean_string(text)\n",
    "    ing_list = string_to_list(text_result)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"-----\")\n",
    "        print(text_result)\n",
    "        \n",
    "    # Loading ingredient dataframe\n",
    "    \n",
    "    df_cosing = pd.read_csv(cosing_path) #'../Database/ingredient_cosing_37309.csv'\n",
    "    # fd_cosing\n",
    "    cosing_dict = {name.strip(): name.strip() for name in df_cosing['ingredient_name']}\n",
    "    fd_cosing = FuzzyDict(cosing_dict, cutoff = .6)\n",
    "    match_dict_cosing = fuzzy_match_ingredients(ing_list, fd_cosing)\n",
    "    \n",
    "    # Input for later models: KNN and randomforest\n",
    "    model_input = [[name for name in match_dict_cosing.values()]]\n",
    "    \n",
    "    # fd main\n",
    "    if language == 'Vietnamese':\n",
    "        df_cmd = pd.read_csv(cmd_path) # Vietnamese database\n",
    "        cmd_dict = {name.strip(): name.strip() for name in df_cmd['ingredient_name']}\n",
    "        fd_cmd = FuzzyDict(cmd_dict, cutoff = .7)\n",
    "        match_dict_fuzzy = fuzzy_match_ingredients(ing_list, fd_cmd)\n",
    "        \n",
    "    else:\n",
    "        df_inci = pd.read_csv(inci_path) # '../Database/CALLMEDUY/ingredient_vietnamese_3818.csv'\n",
    "        inci_dict = {name.strip(): name.strip() for name in df_inci['ingredient_name']}\n",
    "        fd_inci = FuzzyDict(inci_dict, cutoff = .7)\n",
    "        match_dict_fuzzy = fuzzy_match_ingredients(ing_list, fd_inci)\n",
    "\n",
    "    \n",
    "    # Compare product ingredient list and database\n",
    "    # match_dict = find_matching_ingredient(ing_list, rating, 0.55)\n",
    "    \n",
    "    if debug:\n",
    "        print(match_dict_fuzzy)\n",
    "        print(list(match_dict_fuzzy.values()))\n",
    "\n",
    "    if debug:\n",
    "        print(\"length match_dict_fuzzy\", len(match_dict_fuzzy))\n",
    "        print(\"length match_dict_extra\", len(match_dict_cosing))\n",
    "    \n",
    "    # Analyzing ingredient\n",
    "    if language == 'Vietnamese':\n",
    "        df_res = lookup_all_vietnamese(ing_list, match_dict_fuzzy, match_dict_cosing, df_cmd, df_cosing)\n",
    "    \n",
    "    else:\n",
    "        df_res = lookup_all_english(ing_list, match_dict_fuzzy, match_dict_cosing, df_inci, df_cosing)\n",
    "        \n",
    "    return df_res, model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " “co LOW ifritation. Free of fragrances, Ween and mineral oil Yirections: Wet your palma and squeeza a smal amount « ito palm. Lather with water and massaga gently onto fice. Rinse thoroughly with water, ingredients: Water, Laurie Acid. Glycerin, Stearic Acid, Tocamidopropyl Belaine/ Water, Potassium Hydroxide, Butylene Glyool, Paimitie Acid, Acriates Copolymer / Water, Glycol Distearate, Polyquaternium-7, Sodium Laureth Sulfate, Cocamida DEA, Potassium Cocov’ Glycinate f Water, Stearic Acid / Disteardimonium Hectorite, Disodium EDTA, Mathyllsothiazolinone / lodopropyny! Butyicarbamate / Water, Glycerin / Water / Epiloblum Fleischet Eeract / Citic Acid Sodium Hyaluronate D Mported by-_| Dimport oleh: “eK Pharma Pte Lid Rohto-Mantholatum (Mf) Sdn Shd jg OL North Way #0101 (54691-L) Sa%i9 AGA ZN. ‘Unt 9-1, Level 9, Wisma 7 “S48 nina    69200 Kuala Lump Net te eae Ub8nBed by Rol lutica! Co, Jae? if [ie PTvErrnisce WAG manitachc| Ratu (China) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "“ co LOW ifritation . Free fragrances , Ween mineral oil Yirections : Wet palma squeeza smal amount « ito palm . Lather water massaga gently onto fice . Rinse thoroughly water , ingredients : Water , Laurie Acid . Glycerin , Stearic Acid , Tocamidopropyl Belaine/ Water , Potassium Hydroxide , Butylene Glyool , Paimitie Acid , Acriates Copolymer / Water , Glycol Distearate , Polyquaternium-7 , Sodium Laureth Sulfate , Cocamida DEA , Potassium Cocov ’ Glycinate f Water , Stearic Acid / Disteardimonium Hectorite , Disodium EDTA , Mathyllsothiazolinone / lodopropyny ! Butyicarbamate / Water , Glycerin / Water / Epiloblum Fleischet Eeract / Citic Acid Sodium Hyaluronate D Mported by- Dimport : “ eK Pharma Pte Lid Rohto-Mantholatum ( Mf ) Sdn Shd jg OL North Way # 0101 ( 54691-L ) Sa % i9 AGA ZN . ‘ Unt 9-1 , Level 9 , Wisma 7 “ S48 nina 69200 Kuala Lump Net eae Ub8nBed Rol lutica ! Co , Jae ? [ ie PTvErrnisce WAG manitachc Ratu ( China )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 171.70it/s]\n",
      "  9%|▉         | 1/11 [00:00<00:01,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'“ co low ifritation': 'unknown', 'free fragrances': 'FRAGRANCE', 'ween mineral oil yirections : wet palma squeeza smal amount « ito palm': 'unknown', 'lather water massaga gently onto fice': 'unknown', 'rinse thoroughly water': 'unknown', 'ingredients : water': 'unknown', 'laurie acid': 'LAURIC ACID', 'glycerin': 'GLYCERIN', 'stearic acid': 'STEARIC ACID', 'tocamidopropyl belaine/ water': 'COCAMIDOPROPYL BETAINE', 'potassium hydroxide': 'POTASSIUM HYDROXIDE', 'butylene glyool': 'BUTYLENE GLYCOL', 'paimitie acid': 'PALMITIC ACID', 'acriates copolymer / water': 'ACRYLATES COPOLYMER', 'glycol distearate': 'GLYCOL DISTEARATE', 'polyquaternium-7': 'POLYQUATERNIUM-37', 'sodium laureth sulfate': 'SODIUM LAURETH SULFATE', 'cocamida dea': 'COCAMIDE DEA', 'potassium cocov ’ glycinate f water': 'POTASSIUM COCOYL GLYCINATE', 'stearic acid / disteardimonium hectorite': 'DISTEARDIMONIUM HECTORITE', 'disodium edta': 'DISODIUM EDTA', 'mathyllsothiazolinone / lodopropyny ! butyicarbamate / water': 'unknown', 'glycerin / water / epiloblum fleischet eeract / citic acid sodium hyaluronate d mported by- dimport : “ ek pharma pte lid rohto-mantholatum ( mf ) sdn shd jg ol north way # 0101 ( 54691-l ) sa % i9 aga zn': 'unknown', '‘ unt 9-1': 'unknown', 'level 9': 'unknown', 'wisma 7 “ s48 nina 69200 kuala lump net eae ub8nbed rol lutica ! co': 'unknown', 'jae ? [ ie ptverrnisce wag manitachc ratu ( china )': 'unknown'}\n",
      "['unknown', 'FRAGRANCE', 'unknown', 'unknown', 'unknown', 'unknown', 'LAURIC ACID', 'GLYCERIN', 'STEARIC ACID', 'COCAMIDOPROPYL BETAINE', 'POTASSIUM HYDROXIDE', 'BUTYLENE GLYCOL', 'PALMITIC ACID', 'ACRYLATES COPOLYMER', 'GLYCOL DISTEARATE', 'POLYQUATERNIUM-37', 'SODIUM LAURETH SULFATE', 'COCAMIDE DEA', 'POTASSIUM COCOYL GLYCINATE', 'DISTEARDIMONIUM HECTORITE', 'DISODIUM EDTA', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  5.73it/s]\n",
      "1531it [00:00, 7805.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length match_dict_fuzzy 27\n",
      "length match_dict_extra 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1570it [00:00, 7509.74it/s]\n",
      "37309it [00:03, 11041.70it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 59322.27it/s]\n"
     ]
    }
   ],
   "source": [
    "resdf = ocr_everything(fi, ftxt, 'Database/INCI/ingredient_inci_1570.csv', 'Database/ingredient_cosing_37309.csv', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ingredient_name</th>\n",
       "      <th>Functions</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Irritancy</th>\n",
       "      <th>Comedogenicity</th>\n",
       "      <th>Quick_facts</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRAGRANCE</td>\n",
       "      <td>{'perfuming': '/ingredient-functions/perfuming'}</td>\n",
       "      <td>icky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Exactly what it sounds: nice smelling stuff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALPINIA URAIENSIS LEAF WATER</td>\n",
       "      <td>FRAGRANCE, HUMECTANT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Alpinia Uraiensis Leaf Water is the aqueous so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LAURIC ACID</td>\n",
       "      <td>{'anti-acne': '/ingredient-functions/anti-acne...</td>\n",
       "      <td>goodie</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"A 12 carbon length fatty acid that can be fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GLYCERIN</td>\n",
       "      <td>{'skin-identical ingredient': '/ingredient-fun...</td>\n",
       "      <td>superstar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['A natural moisturizer that’s also in our ski...</td>\n",
       "      <td>['Glycerin doesn’t sound very glamorous but it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STEARIC ACID</td>\n",
       "      <td>{'emollient': '/ingredient-functions/emollient...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A common multi-tasker fatty acid. It makes y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COCAMIDOPROPYL BETAINE</td>\n",
       "      <td>{'surfactant/cleansing': '/ingredient-function...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Super common ingredient in all kinds of clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>POTASSIUM HYDROXIDE</td>\n",
       "      <td>{'buffering': '/ingredient-functions/buffering'}</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"It's a very alkaline stuff that helps to set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BUTYLENE GLYCOL</td>\n",
       "      <td>{'moisturizer/humectant': '/ingredient-functio...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Butylene glycol, or let’s just call it BG, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PALMITIC ACID</td>\n",
       "      <td>{'skin-identical ingredient': '/ingredient-fun...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"A fatty acid that can be found naturally in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ACRYLATES COPOLYMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A film-forming polymer (big molecule from re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GLYCOL DISTEARATE</td>\n",
       "      <td>{'emollient': '/ingredient-functions/emollient...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A so-called diester created from two stearic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>POLYQUATERNIUM-37</td>\n",
       "      <td>{'viscosity controlling': '/ingredient-functio...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A cationic polymer molecule (a big molecule ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SODIUM LAURETH SULFATE</td>\n",
       "      <td>{'surfactant/cleansing': '/ingredient-function...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['It’s probably the most common cleansing ingr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COCAMIDE DEA</td>\n",
       "      <td>{'surfactant/cleansing': '/ingredient-function...</td>\n",
       "      <td>icky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A cleansing agent whose main thing is being ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>POTASSIUM COCOYL GLYCINATE</td>\n",
       "      <td>{'surfactant/cleansing': '/ingredient-function...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['An amino-acid\\xa0based cleansing agent that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DISTEARDIMONIUM HECTORITE</td>\n",
       "      <td>{'viscosity controlling': '/ingredient-functio...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['An organic derivative of hectorite clay, Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DISODIUM EDTA</td>\n",
       "      <td>{'chelating': '/ingredient-functions/chelating...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Super common little helper ingredient that\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LEVOMENOL</td>\n",
       "      <td>FRAGRANCE, SKIN CONDITIONING, SOOTHING</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>(R*,R*)-.alpha.,4-dimethyl-.alpha.-(4-methyl-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Ingredient_name  \\\n",
       "0                        unknown   \n",
       "1                      FRAGRANCE   \n",
       "2                        unknown   \n",
       "3                        unknown   \n",
       "4                        unknown   \n",
       "5   ALPINIA URAIENSIS LEAF WATER   \n",
       "6                    LAURIC ACID   \n",
       "7                       GLYCERIN   \n",
       "8                   STEARIC ACID   \n",
       "9         COCAMIDOPROPYL BETAINE   \n",
       "10           POTASSIUM HYDROXIDE   \n",
       "11               BUTYLENE GLYCOL   \n",
       "12                 PALMITIC ACID   \n",
       "13           ACRYLATES COPOLYMER   \n",
       "14             GLYCOL DISTEARATE   \n",
       "15             POLYQUATERNIUM-37   \n",
       "16        SODIUM LAURETH SULFATE   \n",
       "17                  COCAMIDE DEA   \n",
       "18    POTASSIUM COCOYL GLYCINATE   \n",
       "19     DISTEARDIMONIUM HECTORITE   \n",
       "20                 DISODIUM EDTA   \n",
       "21                       unknown   \n",
       "22                       unknown   \n",
       "23                       unknown   \n",
       "24                     LEVOMENOL   \n",
       "25                       unknown   \n",
       "26                       unknown   \n",
       "\n",
       "                                            Functions     Rating Irritancy  \\\n",
       "0                                                  []    unknown   unknown   \n",
       "1    {'perfuming': '/ingredient-functions/perfuming'}       icky       NaN   \n",
       "2                                                  []    unknown   unknown   \n",
       "3                                                  []    unknown   unknown   \n",
       "4                                                  []    unknown   unknown   \n",
       "5                                FRAGRANCE, HUMECTANT    unknown   unknown   \n",
       "6   {'anti-acne': '/ingredient-functions/anti-acne...     goodie         1   \n",
       "7   {'skin-identical ingredient': '/ingredient-fun...  superstar         0   \n",
       "8   {'emollient': '/ingredient-functions/emollient...  No rating         0   \n",
       "9   {'surfactant/cleansing': '/ingredient-function...  No rating       NaN   \n",
       "10   {'buffering': '/ingredient-functions/buffering'}  No rating       NaN   \n",
       "11  {'moisturizer/humectant': '/ingredient-functio...  No rating         0   \n",
       "12  {'skin-identical ingredient': '/ingredient-fun...  No rating         0   \n",
       "13                                                NaN  No rating       NaN   \n",
       "14  {'emollient': '/ingredient-functions/emollient...  No rating       NaN   \n",
       "15  {'viscosity controlling': '/ingredient-functio...  No rating       NaN   \n",
       "16  {'surfactant/cleansing': '/ingredient-function...  No rating       NaN   \n",
       "17  {'surfactant/cleansing': '/ingredient-function...       icky       NaN   \n",
       "18  {'surfactant/cleansing': '/ingredient-function...  No rating       NaN   \n",
       "19  {'viscosity controlling': '/ingredient-functio...  No rating       NaN   \n",
       "20  {'chelating': '/ingredient-functions/chelating...  No rating       NaN   \n",
       "21                                                 []    unknown   unknown   \n",
       "22                                                 []    unknown   unknown   \n",
       "23                                                 []    unknown   unknown   \n",
       "24             FRAGRANCE, SKIN CONDITIONING, SOOTHING    unknown   unknown   \n",
       "25                                                 []    unknown   unknown   \n",
       "26                                                 []    unknown   unknown   \n",
       "\n",
       "         Comedogenicity                                        Quick_facts  \\\n",
       "0               unknown                                            unknown   \n",
       "1                   NaN                                                NaN   \n",
       "2               unknown                                            unknown   \n",
       "3               unknown                                            unknown   \n",
       "4               unknown                                            unknown   \n",
       "5               unknown                                            unknown   \n",
       "6                     4                                                NaN   \n",
       "7                     0  ['A natural moisturizer that’s also in our ski...   \n",
       "8   2020-02-03 00:00:00                                                NaN   \n",
       "9                   NaN                                                NaN   \n",
       "10                  NaN                                                NaN   \n",
       "11                    1                                                NaN   \n",
       "12                    2                                                NaN   \n",
       "13                  NaN                                                NaN   \n",
       "14                  NaN                                                NaN   \n",
       "15                  NaN                                                NaN   \n",
       "16                  NaN                                                NaN   \n",
       "17                  NaN                                                NaN   \n",
       "18                  NaN                                                NaN   \n",
       "19                  NaN                                                NaN   \n",
       "20                  NaN                                                NaN   \n",
       "21              unknown                                            unknown   \n",
       "22              unknown                                            unknown   \n",
       "23              unknown                                            unknown   \n",
       "24              unknown                                            unknown   \n",
       "25              unknown                                            unknown   \n",
       "26              unknown                                            unknown   \n",
       "\n",
       "                                          Description  \n",
       "0                                                  []  \n",
       "1   ['Exactly what it sounds: nice smelling stuff ...  \n",
       "2                                                  []  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "5   Alpinia Uraiensis Leaf Water is the aqueous so...  \n",
       "6   [\"A 12 carbon length fatty acid that can be fo...  \n",
       "7   ['Glycerin doesn’t sound very glamorous but it...  \n",
       "8   ['A common multi-tasker fatty acid. It makes y...  \n",
       "9   ['Super common ingredient in all kinds of clea...  \n",
       "10  [\"It's a very alkaline stuff that helps to set...  \n",
       "11  ['Butylene glycol, or let’s just call it BG, i...  \n",
       "12  [\"A fatty acid that can be found naturally in ...  \n",
       "13  ['A film-forming polymer (big molecule from re...  \n",
       "14  ['A so-called diester created from two stearic...  \n",
       "15  ['A cationic polymer molecule (a big molecule ...  \n",
       "16  ['It’s probably the most common cleansing ingr...  \n",
       "17  ['A cleansing agent whose main thing is being ...  \n",
       "18  ['An amino-acid\\xa0based cleansing agent that ...  \n",
       "19  ['An organic derivative of hectorite clay, Dis...  \n",
       "20  ['Super common little helper ingredient that\\x...  \n",
       "21                                                 []  \n",
       "22                                                 []  \n",
       "23                                                 []  \n",
       "24  (R*,R*)-.alpha.,4-dimethyl-.alpha.-(4-methyl-3...  \n",
       "25                                                 []  \n",
       "26                                                 []  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end(imgfile, inci_path, cosing_path, debug=False):\n",
    "    dewarped_img = page_dewarp(imgfile)\n",
    "    _, ctpn_txt = ctpn(dewarped_img)\n",
    "    return ocr_everything(dewarped_img, ctpn_txt, inci_path, cosing_path, debug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e2e_no_dewarp(imgfile, inci_path, cosing_path, debug=False):\n",
    "    img = cv2.imread(imgfile)\n",
    "    processed_img = preprocess_for_ocr(img)\n",
    "    \n",
    "    basename = os.path.basename(imgfile)\n",
    "    name, _ = os.path.splitext(basename)\n",
    "    output_folder = \"preprocessed\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    output_pp = os.path.join(output_folder, basename)\n",
    "    cv2.imwrite(output_pp, processed_img)\n",
    "    _, ctpn_txt = ctpn(output_pp)\n",
    "    return ocr_everything(imgfile, ctpn_txt, inci_path, cosing_path, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded not_bad_at_coding.jpg with size 1280x794 and resized to 640x397\n",
      "  got 12 spans with 147 points.\n",
      "  initial objective is 0.000983501056451414\n",
      "  optimizing 167 parameters...\n",
      "  optimization took 7.03 sec.\n",
      "  final objective is 0.00025956530201118067\n",
      "  got page dims 1.7380212152528396 x 1.1293530256691877\n",
      "  output will be 704x448\n",
      "Restore from text-detection-ctpn/checkpoints_mlt/ctpn_50000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from text-detection-ctpn/checkpoints_mlt/ctpn_50000.ckpt\n",
      "cost time: 2.66s\n",
      " AVIS UU UIING, UU PU OTT, PUTT TTT a ment. Nourrie e adoucle, votre peou retrouve son éciot naturel Tes dernatologiquenen. Ke pas appliquer sur i¢ visage, 4QLTRA DOUX S'ENGAGE POUR VOUS, Bean ct Wa MUM AU CC MY Wasa 0 ie Ultra Doux s’ engage 4 raspecier une chase de qualite al de bienveilkance. NOUS AVONS frovoilie CCTVEMeN! How vous ¢ Offtis des formules bonnes pour votre peau et de plus en plus respectueuses de lo planéta, an associan! notomment dé ia stveérine vegetole of Gu beurre de karilé issu d'un comme: équitable, INPRITUEL DE SOIN ADOUCISSANT Déecouvrez Gussi Note Douche Soin nourrissante ef assoulissanie, qui fe Lott de Coco 0d lo Nok de Mocodomid, pour une peau nadie foul en couceur. CTS 5 ~ INGREDIENTS : AIA! WATER, GLYCERIN, PARUFEINUM LIDUIDUM / MURAL OF GUTYROOPO IMUM PAID UTTER (SHEA SUTTER CETEARYL ALCOHOL DIMETHICOME CARRY YL GLICK CARMAN CARROREA 0 10709 / IRTL mi\n",
      "aor t CCERA EMIT EXTRACT COCOM IT FRIIT XTRAS GIYCHEM VIP AD, (OCIS Wi STEAMATE, MACAD#MiR TERNIFOLIA SEED CHL, MYSTIC ACID, PALMITIC AGED, Z28RO01 FEG-i00 STEARATE. “HEMONY ETHANOL POTASSIUM SORBATE. PRUMUS AMYGDALLS WULCIS OM.‘ SWEET ALMOND OIL SODIUM HYDROMIDE, STEARIC ACID, XANTHAN <i, PAPUA / PRUNES oF |. 821364771), au) | GARNIER = —O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "AVIS UU UIING , UU PU OTT , PUTT TTT ment . Nourrie adoucle , peou retrouve éciot naturel Tes dernatologiquenen . Ke appliquer i¢ visage , 4QLTRA DOUX SENGAGE POUR VOUS , Bean ct Wa MUM AU CC MY Wasa 0 ie Ultra Doux ’ engage 4 raspecier chase qualite bienveilkance . NOUS AVONS frovoilie CCTVEMeN ! How ¢ Offtis formules bonnes peau plus plus respectueuses planéta , associan ! notomment dé stveérine vegetole Gu beurre karilé issu dun comme : équitable , INPRITUEL DE SOIN ADOUCISSANT Déecouvrez Gussi Note Douche Soin nourrissante ef assoulissanie , fe Lott Coco 0d Nok Mocodomid , peau nadie foul couceur . CTS 5 ~ INGREDIENTS : AIA ! WATER , GLYCERIN , PARUFEINUM LIDUIDUM / MURAL OF GUTYROOPO IMUM PAID UTTER ( SHEA SUTTER CETEARYL ALCOHOL DIMETHICOME CARRY YL GLICK CARMAN CARROREA 0 10709 / IRTL aor CCERA EMIT EXTRACT COCOM IT FRIIT XTRAS GIYCHEM VIP AD , ( OCIS Wi STEAMATE , MACAD # MiR TERNIFOLIA SEED CHL , MYSTIC ACID , PALMITIC AGED , Z28RO01 FEG-i00 STEARATE . “ HEMONY ETHANOL POTASSIUM SORBATE . PRUMUS AMYGDALLS WULCIS OM. ‘ SWEET ALMOND OIL SODIUM HYDROMIDE , STEARIC ACID , XANTHAN < , PAPUA / PRUNES oF . 821364771 ) , ) GARNIER = —O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 124.55it/s]\n",
      "  5%|▍         | 1/21 [00:00<00:02,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avis uu uiing': 'unknown', 'uu pu ott': 'unknown', 'putt ttt ment': 'unknown', 'nourrie adoucle': 'unknown', 'peou retrouve éciot naturel tes dernatologiquenen': 'unknown', 'ke appliquer i¢ visage': 'unknown', '4qltra doux sengage pour vous': 'unknown', 'bean ct wa mum au cc my wasa 0 ie ultra doux ’ engage 4 raspecier chase qualite bienveilkance': 'unknown', 'nous avons frovoilie cctvemen ! how ¢ offtis formules bonnes peau plus plus respectueuses planéta': 'unknown', 'associan ! notomment dé stveérine vegetole gu beurre karilé issu dun comme : équitable': 'unknown', 'inprituel de soin adoucissant déecouvrez gussi note douche soin nourrissante ef assoulissanie': 'unknown', 'fe lott coco 0d nok mocodomid': 'unknown', 'peau nadie foul couceur': 'unknown', 'cts 5 ~ ingredients : aia ! water': 'unknown', 'glycerin': 'GLYCERIN', 'parufeinum liduidum / mural of gutyroopo imum paid utter ( shea sutter cetearyl alcohol dimethicome carry yl glick carman carrorea 0 10709 / irtl aor ccera emit extract cocom it friit xtras giychem vip ad': 'unknown', '( ocis wi steamate': 'unknown', 'macad # mir ternifolia seed chl': 'MACADAMIA TERNIFOLIA SEED OIL', 'mystic acid': 'MYRISTIC ACID', 'palmitic aged': 'PALMITIC ACID', 'z28ro01 feg-i00 stearate': 'PEG-100 STEARATE', '“ hemony ethanol potassium sorbate': 'unknown', 'prumus amygdalls wulcis om': 'PRUNUS AMYGDALUS DULCIS OIL', '‘ sweet almond oil sodium hydromide': 'unknown', 'stearic acid': 'STEARIC ACID', 'xanthan <': 'XANTHAN GUM', 'papua / prunes of': 'unknown', '821364771 )': 'unknown', ') garnier = —o': 'unknown'}\n",
      "['unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'GLYCERIN', 'unknown', 'unknown', 'MACADAMIA TERNIFOLIA SEED OIL', 'MYRISTIC ACID', 'PALMITIC ACID', 'PEG-100 STEARATE', 'unknown', 'PRUNUS AMYGDALUS DULCIS OIL', 'unknown', 'STEARIC ACID', 'XANTHAN GUM', 'unknown', 'unknown', 'unknown']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:03<00:00,  6.17it/s]\n",
      "692it [00:00, 6909.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length match_dict_fuzzy 29\n",
      "length match_dict_extra 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1570it [00:00, 6784.75it/s]\n",
      "37309it [00:03, 9831.50it/s] \n",
      "100%|██████████| 29/29 [00:00<00:00, 75549.58it/s]\n"
     ]
    }
   ],
   "source": [
    "test_res = end_to_end(\"Sample_images/not_bad_at_coding.jpg\", \n",
    "                      'Database/INCI/ingredient_inci_1570.csv', \n",
    "                      'Database/ingredient_cosing_37309.csv', \n",
    "                      debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ingredient_name</th>\n",
       "      <th>Functions</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Irritancy</th>\n",
       "      <th>Comedogenicity</th>\n",
       "      <th>Quick_facts</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLYCERIN</td>\n",
       "      <td>{'skin-identical ingredient': '/ingredient-fun...</td>\n",
       "      <td>superstar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['A natural moisturizer that’s also in our ski...</td>\n",
       "      <td>['Glycerin doesn’t sound very glamorous but it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISOSTEARATE</td>\n",
       "      <td>HUMECTANT, SKIN CONDITIONING</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fatty acids, C18-unsatd., dimers, hydrogenated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MACADAMIA TERNIFOLIA SEED OIL</td>\n",
       "      <td>{'emollient': '/ingredient-functions/emollient'}</td>\n",
       "      <td>goodie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"The golden yellow oil coming from the Macada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MYRISTIC ACID</td>\n",
       "      <td>{'surfactant/cleansing': '/ingredient-function...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"A 14 carbon length fatty acid that can be na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PALMITIC ACID</td>\n",
       "      <td>{'skin-identical ingredient': '/ingredient-fun...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"A fatty acid that can be found naturally in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PEG-100 STEARATE</td>\n",
       "      <td>{'surfactant/cleansing': '/ingredient-function...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A very common water-loving surfactant and em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>POTASSIUM SORBATE</td>\n",
       "      <td>FRAGRANCE, PRESERVATIVE</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Potassium (E,E)-hexa-2,4-dienoate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRUNUS AMYGDALUS DULCIS OIL</td>\n",
       "      <td>{'emollient': '/ingredient-functions/emollient'}</td>\n",
       "      <td>goodie</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['The emollient plant oil that comes from almo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SWEET ALMOND OIL</td>\n",
       "      <td>EMULSION STABILISING, HAIR CONDITIONING, HUMEC...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Pseudozyma Epicola/Soybean Flour/Apricot Kerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STEARIC ACID</td>\n",
       "      <td>{'emollient': '/ingredient-functions/emollient...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A common multi-tasker fatty acid. It makes y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XANTHAN GUM</td>\n",
       "      <td>{'viscosity controlling': '/ingredient-functio...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"It's one of the most commonly used thickener...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ingredient_name  \\\n",
       "0                        GLYCERIN   \n",
       "1                     ISOSTEARATE   \n",
       "2   MACADAMIA TERNIFOLIA SEED OIL   \n",
       "3                   MYRISTIC ACID   \n",
       "4                   PALMITIC ACID   \n",
       "5                PEG-100 STEARATE   \n",
       "6               POTASSIUM SORBATE   \n",
       "7     PRUNUS AMYGDALUS DULCIS OIL   \n",
       "8                SWEET ALMOND OIL   \n",
       "9                    STEARIC ACID   \n",
       "10                    XANTHAN GUM   \n",
       "\n",
       "                                            Functions     Rating Irritancy  \\\n",
       "0   {'skin-identical ingredient': '/ingredient-fun...  superstar         0   \n",
       "1                        HUMECTANT, SKIN CONDITIONING    unknown   unknown   \n",
       "2    {'emollient': '/ingredient-functions/emollient'}     goodie       NaN   \n",
       "3   {'surfactant/cleansing': '/ingredient-function...  No rating         0   \n",
       "4   {'skin-identical ingredient': '/ingredient-fun...  No rating         0   \n",
       "5   {'surfactant/cleansing': '/ingredient-function...  No rating         0   \n",
       "6                             FRAGRANCE, PRESERVATIVE    unknown   unknown   \n",
       "7    {'emollient': '/ingredient-functions/emollient'}     goodie         0   \n",
       "8   EMULSION STABILISING, HAIR CONDITIONING, HUMEC...    unknown   unknown   \n",
       "9   {'emollient': '/ingredient-functions/emollient...  No rating         0   \n",
       "10  {'viscosity controlling': '/ingredient-functio...  No rating       NaN   \n",
       "\n",
       "         Comedogenicity                                        Quick_facts  \\\n",
       "0                     0  ['A natural moisturizer that’s also in our ski...   \n",
       "1               unknown                                            unknown   \n",
       "2                   NaN                                                NaN   \n",
       "3                     3                                                NaN   \n",
       "4                     2                                                NaN   \n",
       "5                     0                                                NaN   \n",
       "6               unknown                                            unknown   \n",
       "7   2020-01-03 00:00:00                                                NaN   \n",
       "8               unknown                                            unknown   \n",
       "9   2020-02-03 00:00:00                                                NaN   \n",
       "10                  NaN                                                NaN   \n",
       "\n",
       "                                          Description  \n",
       "0   ['Glycerin doesn’t sound very glamorous but it...  \n",
       "1   Fatty acids, C18-unsatd., dimers, hydrogenated...  \n",
       "2   [\"The golden yellow oil coming from the Macada...  \n",
       "3   [\"A 14 carbon length fatty acid that can be na...  \n",
       "4   [\"A fatty acid that can be found naturally in ...  \n",
       "5   ['A very common water-loving surfactant and em...  \n",
       "6                   Potassium (E,E)-hexa-2,4-dienoate  \n",
       "7   ['The emollient plant oil that comes from almo...  \n",
       "8   Pseudozyma Epicola/Soybean Flour/Apricot Kerne...  \n",
       "9   ['A common multi-tasker fatty acid. It makes y...  \n",
       "10  [\"It's one of the most commonly used thickener...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore from text-detection-ctpn/checkpoints_mlt/ctpn_50000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from text-detection-ctpn/checkpoints_mlt/ctpn_50000.ckpt\n",
      "cost time: 2.84s\n",
      " fexture UNTO TONGUTHS, UU PUTTUITT QUGrTTRaTy, | A Ww ment. Nourrie et adoucie, votre peau retrouve son éciat nature! Testé dermatologiquement. Ne pas appliquer sur le visage, | ULTRA DOUX S’ENGAGE POUR VOUS, POUR BATIR UN AVENIR MEILLEUR Ultra Doux s‘engage 4 respecter une charte de qualité et ¢: gt Oe... bienveillance. Nous avons travaillé activement pour yo. -  offrir des formules bonnes pour votre peau et de plus «- « plus respectueuses de la planéte, en associant notamme —_ rs do in otyeérine véegétale et du beurre de karité issu ¢ 0 Pow'®®” comm: —: equitable. — wo Uwe Découvrez aussi notre Douche Soin nourrissante et assouplissante, qui assoc \\e Lait de Coco 4 la Noix de Macadamia, pour une peau nourrie tout en douceur ny Vi\n",
      "ol 967365 5 - INGREDIENTS ; AQUA / WATER, GLYCERIN. PARAFFINUM LIQUIDUM / MINERAL OIL BUTYROSPERMUM P   | STEARATE, MACADAMIA TERNIFOLIA SEED OIL, MYRISTIC ACID, PALMITIC ACID, 28R001 | PEG-100 STEARATE. PMENOXYETHANOL POTASSIUM SORBATE PRUNUS AMYGDALUS AMTHAN, | DULCIS Ol. / SWEET ALMOND ON SODIUM HYDROXIDE. STEARIC + ACID, KF GUM. PAREUM | FRAGRANCE (FL. 8213547) ). ° w ic aun GARNIER :- 2\\O vous conseille\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "fexture UNTO TONGUTHS , UU PUTTUITT QUGrTTRaTy , A Ww ment . Nourrie adoucie , peau retrouve éciat nature ! Testé dermatologiquement . Ne appliquer visage , ULTRA DOUX S ’ ENGAGE POUR VOUS , POUR BATIR UN AVENIR MEILLEUR Ultra Doux ‘ engage 4 respecter charte qualité ¢ : gt Oe ... bienveillance . Nous travaillé activement . - offrir formules bonnes peau plus « - « plus respectueuses planéte , associant notamme — rs otyeérine véegétale beurre karité issu ¢ 0 Pow®® ” comm : — : equitable . — Uwe Découvrez aussi Douche Soin nourrissante assouplissante , assoc Lait Coco 4 Noix Macadamia , peau nourrie tout douceur ny Vi ol 967365 5 - INGREDIENTS ; AQUA / WATER , GLYCERIN . PARAFFINUM LIQUIDUM / MINERAL OIL BUTYROSPERMUM P STEARATE , MACADAMIA TERNIFOLIA SEED OIL , MYRISTIC ACID , PALMITIC ACID , 28R001 PEG-100 STEARATE . PMENOXYETHANOL POTASSIUM SORBATE PRUNUS AMYGDALUS AMTHAN , DULCIS Ol . / SWEET ALMOND ON SODIUM HYDROXIDE . STEARIC + ACID , KF GUM . PAREUM FRAGRANCE ( FL . 8213547 ) ) . ° w ic aun GARNIER : - 2 O conseille\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 160.26it/s]\n",
      "  4%|▍         | 1/23 [00:00<00:02,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fexture unto tonguths': 'unknown', 'uu puttuitt qugrttraty': 'unknown', 'a ww ment': 'unknown', 'nourrie adoucie': 'unknown', 'peau retrouve éciat nature ! testé dermatologiquement': 'unknown', 'ne appliquer visage': 'unknown', 'ultra doux s ’ engage pour vous': 'unknown', 'pour batir un avenir meilleur ultra doux ‘ engage 4 respecter charte qualité ¢ : gt oe': 'unknown', '': 'unknown', 'bienveillance': 'unknown', 'nous travaillé activement': 'unknown', '- offrir formules bonnes peau plus « - « plus respectueuses planéte': 'unknown', 'associant notamme — rs otyeérine véegétale beurre karité issu ¢ 0 pow®® ” comm : — : equitable': 'unknown', '— uwe découvrez aussi douche soin nourrissante assouplissante': 'unknown', 'assoc lait coco 4 noix macadamia': 'unknown', 'peau nourrie tout douceur ny vi ol 967365 5 - ingredients ; aqua / water': 'unknown', 'glycerin': 'GLYCERIN', 'paraffinum liquidum / mineral oil butyrospermum p stearate': 'unknown', 'macadamia ternifolia seed oil': 'MACADAMIA TERNIFOLIA SEED OIL', 'myristic acid': 'MYRISTIC ACID', 'palmitic acid': 'PALMITIC ACID', '28r001 peg-100 stearate': 'PEG-100 STEARATE', 'pmenoxyethanol potassium sorbate prunus amygdalus amthan': 'unknown', 'dulcis ol': 'unknown', '/ sweet almond on sodium hydroxide': 'unknown', 'stearic + acid': 'STEARIC ACID', 'kf gum': 'unknown', 'pareum fragrance ( fl': 'PARFUM/ FRAGRANCE', '8213547 ) )': 'unknown', '° w ic aun garnier : - 2 o conseille': 'unknown'}\n",
      "['unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'GLYCERIN', 'unknown', 'MACADAMIA TERNIFOLIA SEED OIL', 'MYRISTIC ACID', 'PALMITIC ACID', 'PEG-100 STEARATE', 'unknown', 'unknown', 'unknown', 'STEARIC ACID', 'unknown', 'PARFUM/ FRAGRANCE', 'unknown', 'unknown']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:03<00:00,  6.89it/s]\n",
      "1570it [00:00, 8042.75it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length match_dict_fuzzy 30\n",
      "length match_dict_extra 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37309it [00:03, 10176.13it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 77858.34it/s]\n"
     ]
    }
   ],
   "source": [
    "test_res = e2e_no_dewarp(\"Sample_images/not_bad_at_coding.jpg\", \n",
    "                      'Database/INCI/ingredient_inci_1570.csv', \n",
    "                      'Database/ingredient_cosing_37309.csv', \n",
    "                      debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ingredient_name</th>\n",
       "      <th>Functions</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Irritancy</th>\n",
       "      <th>Comedogenicity</th>\n",
       "      <th>Quick_facts</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAC FERMENT</td>\n",
       "      <td>SKIN CONDITIONING</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Lactobacillus/Lac Ferment is a product obtaine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLYCERIN</td>\n",
       "      <td>{'skin-identical ingredient': '/ingredient-fun...</td>\n",
       "      <td>superstar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['A natural moisturizer that’s also in our ski...</td>\n",
       "      <td>['Glycerin doesn’t sound very glamorous but it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MACADAMIA TERNIFOLIA SEED OIL</td>\n",
       "      <td>{'emollient': '/ingredient-functions/emollient'}</td>\n",
       "      <td>goodie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"The golden yellow oil coming from the Macada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MYRISTIC ACID</td>\n",
       "      <td>{'surfactant/cleansing': '/ingredient-function...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"A 14 carbon length fatty acid that can be na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PALMITIC ACID</td>\n",
       "      <td>{'skin-identical ingredient': '/ingredient-fun...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"A fatty acid that can be found naturally in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PEG-100 STEARATE</td>\n",
       "      <td>{'surfactant/cleansing': '/ingredient-function...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A very common water-loving surfactant and em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EDULIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Boletus Aereus/Aestivalis/Edulis/Pinicola Extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMMONIUM HYDROXIDE</td>\n",
       "      <td>BUFFERING, DENATURANT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Ammonium hydroxyde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STEARIC ACID</td>\n",
       "      <td>{'emollient': '/ingredient-functions/emollient...</td>\n",
       "      <td>No rating</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['A common multi-tasker fatty acid. It makes y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PARFUM/ FRAGRANCE</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Ingredient_name  \\\n",
       "0                    LAC FERMENT   \n",
       "1                       GLYCERIN   \n",
       "2  MACADAMIA TERNIFOLIA SEED OIL   \n",
       "3                  MYRISTIC ACID   \n",
       "4                  PALMITIC ACID   \n",
       "5               PEG-100 STEARATE   \n",
       "6                         EDULIS   \n",
       "7             AMMONIUM HYDROXIDE   \n",
       "8                   STEARIC ACID   \n",
       "9              PARFUM/ FRAGRANCE   \n",
       "\n",
       "                                           Functions     Rating Irritancy  \\\n",
       "0                                  SKIN CONDITIONING    unknown   unknown   \n",
       "1  {'skin-identical ingredient': '/ingredient-fun...  superstar         0   \n",
       "2   {'emollient': '/ingredient-functions/emollient'}     goodie       NaN   \n",
       "3  {'surfactant/cleansing': '/ingredient-function...  No rating         0   \n",
       "4  {'skin-identical ingredient': '/ingredient-fun...  No rating         0   \n",
       "5  {'surfactant/cleansing': '/ingredient-function...  No rating         0   \n",
       "6                                                NaN    unknown   unknown   \n",
       "7                              BUFFERING, DENATURANT    unknown   unknown   \n",
       "8  {'emollient': '/ingredient-functions/emollient...  No rating         0   \n",
       "9                                                 []    unknown   unknown   \n",
       "\n",
       "        Comedogenicity                                        Quick_facts  \\\n",
       "0              unknown                                            unknown   \n",
       "1                    0  ['A natural moisturizer that’s also in our ski...   \n",
       "2                  NaN                                                NaN   \n",
       "3                    3                                                NaN   \n",
       "4                    2                                                NaN   \n",
       "5                    0                                                NaN   \n",
       "6              unknown                                            unknown   \n",
       "7              unknown                                            unknown   \n",
       "8  2020-02-03 00:00:00                                                NaN   \n",
       "9              unknown                                                 []   \n",
       "\n",
       "                                         Description  \n",
       "0  Lactobacillus/Lac Ferment is a product obtaine...  \n",
       "1  ['Glycerin doesn’t sound very glamorous but it...  \n",
       "2  [\"The golden yellow oil coming from the Macada...  \n",
       "3  [\"A 14 carbon length fatty acid that can be na...  \n",
       "4  [\"A fatty acid that can be found naturally in ...  \n",
       "5  ['A very common water-loving surfactant and em...  \n",
       "6  Boletus Aereus/Aestivalis/Edulis/Pinicola Extr...  \n",
       "7                                 Ammonium hydroxyde  \n",
       "8  ['A common multi-tasker fatty acid. It makes y...  \n",
       "9                                                 []  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
